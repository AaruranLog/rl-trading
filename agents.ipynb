{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaruran/miniconda3/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "from system import TradingEnv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory) > self.capacity:\n",
    "            del self.memory[0]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TradingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vlu9wCHd-oVS"
   },
   "outputs": [],
   "source": [
    "STATE_DIM = len(e.reset())\n",
    "ACTION_DIM = 3\n",
    "EPISODES = 2000  # number of episodes\n",
    "EPS_START = 0.9  # e-greedy threshold start value\n",
    "EPS_END = 0.05  # e-greedy threshold end value\n",
    "EPS_DECAY = 200  # e-greedy threshold decay\n",
    "GAMMA = 0.99  # Q-learning discount factor\n",
    "LR = 0.001  # NN optimizer learning rate\n",
    "HIDDEN_LAYER = 10  # NN hidden layer size\n",
    "BATCH_SIZE = 500  # Q-learning batch size\n",
    "TARGET_UPDATE = 100  # frequency of target update\n",
    "BUFFER_SIZE = 10000  # capacity of the replay buffer \n",
    "\n",
    "# if gpu is to be used\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU will be used\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    print('GPU found and in use')\n",
    "else:\n",
    "    print('No GPU will be used')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MA7IgkTA_Jsp"
   },
   "source": [
    "# Simple QNetwork \n",
    "Corresponds to a fully connected network with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpkLvLcR_WOl"
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(STATE_DIM, HIDDEN_LAYER)\n",
    "        self.l2 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "        self.l3 = nn.Linear(HIDDEN_LAYER, ACTION_DIM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            Computes the estimated Q-values for a given batch x\n",
    "        \"\"\"\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x      \n",
    "    \n",
    "    def sample_from_softmax_policy(self, batch_state):\n",
    "        batch_q_values = self.forward(batch_state)\n",
    "        batch_pi = F.softmax(batch_q_values, dim=1)\n",
    "        batch_size = batch_pi.shape[0]\n",
    "        batch_actions = torch.empty(batch_size, 1)\n",
    "        for i in range(batch_size):\n",
    "            pi = batch_pi[i, :]\n",
    "            dist = torch.distributions.Categorical(pi)\n",
    "            # Subtract 1, so batch_actions is in {-1, 0, 1}\n",
    "            batch_actions[i, 0] = dist.sample().view(1,1) - 1\n",
    "        if use_cuda:\n",
    "            batch_actions = batch_actions.to(batch_state.get_device())\n",
    "        return batch_actions.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Training Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    def __init__(self, gamma=0.8):\n",
    "        assert 0 < gamma < 1, f\"Invalid gamma: {gamma}\" \n",
    "        self.gamma = gamma\n",
    "        self.memory = ReplayMemory(BUFFER_SIZE)\n",
    "        self.rewards_history = []\n",
    "        \n",
    "    def run_episode(self, environment):\n",
    "        \"\"\"\n",
    "            Takes an env, and trains the agent until the environment\n",
    "            reaches a terminal state (ie the training window is complete).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def plot_cumulative_discounted_rewards(self):\n",
    "        \"\"\"\n",
    "            rewards_list: a list of lists, with shape n_episodes x n_steps\n",
    "        \"\"\"\n",
    "        rewards = np.array(self.rewards_history)\n",
    "        discount_array = np.power(0.8, np.arange(rewards.shape[0]))\n",
    "        plt.plot((discount_array[:, None] * rewards).sum(axis=1))\n",
    "        plt.grid()\n",
    "        plt.ylabel('Cumulative Discounted Rewards')\n",
    "        plt.xlabel('Episode')\n",
    "\n",
    "    def convert_action(self, action):\n",
    "        \"\"\"\n",
    "            Takes action of shape 1 x 3, and converts into an integer in {-1, 0, 1}.\n",
    "            This integer is the position short/hold/long respectively.\n",
    "        \"\"\"\n",
    "        position = torch.argmax(action, dim=-1) - 1\n",
    "        assert position in [-1,0,1]\n",
    "        return position\n",
    "        \n",
    "class DQN(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = QNetwork()\n",
    "        self.target = QNetwork()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), LR)\n",
    "        self.steps_done = 0\n",
    "\n",
    "    def select_epsilon_greedy_action(self, state):\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * self.steps_done / EPS_DECAY)\n",
    "        self.steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                return self.target(state).data.max(1)[1].view(1, 1)\n",
    "        else:\n",
    "            return LongTensor([[random.randrange(3)]])\n",
    "    \n",
    "    def run_episode(self, environment):\n",
    "        state = environment.reset()\n",
    "        steps = 0\n",
    "        action = None\n",
    "        while True:\n",
    "#             if steps % 50 == 0:\n",
    "#                 print(f'steps = {steps}')\n",
    "            state_tensor = FloatTensor([state])\n",
    "            action = self.select_epsilon_greedy_action(state_tensor)\n",
    "            position = self.convert_action(action)\n",
    "            next_state, reward, done, _ = environment.step(position)\n",
    "#             print(f'action = {action}')            \n",
    "#             print(f'position = {position}')\n",
    "#             print(f'next_state length = {len(next_state)}')\n",
    "#             print(f'reward = {reward}')\n",
    "            self.memory.push((FloatTensor([state]),\n",
    "                         action,  # action is already a tensor\n",
    "                         FloatTensor([next_state]),\n",
    "                         FloatTensor([reward]),\n",
    "                         FloatTensor([int(done)])))\n",
    "\n",
    "            self.learn()\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            if done:\n",
    "                break\n",
    "        self.rewards_history.append(environment.rewards_list)\n",
    "        \n",
    "    def max_next_q_values(self, batch_next_state):\n",
    "        # expected Q values are estimated from actions which gives maximum Q value\n",
    "        return self.target(batch_next_state).detach().max(1)[0]\n",
    "    \n",
    "    def learn(self):\n",
    "        if len(self.memory) <= BATCH_SIZE:\n",
    "            return\n",
    "        # random transition batch is taken from experience replay memory\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        batch_state, batch_action, batch_next_state, batch_reward, batch_done = zip(*transitions)\n",
    "        batch_state = Variable(torch.cat(batch_state))\n",
    "        batch_action = Variable(torch.cat(batch_action))\n",
    "        batch_reward = Variable(torch.cat(batch_reward))\n",
    "        batch_next_state = Variable(torch.cat(batch_next_state))\n",
    "        batch_done = Variable(torch.cat(batch_done))\n",
    "\n",
    "        # current Q values are estimated by NN for all actions\n",
    "        current_q_values = self.model(batch_state).gather(1, batch_action).squeeze()\n",
    "        expected_future_rewards = self.max_next_q_values(batch_next_state)\n",
    "        \n",
    "        expected_q_values = batch_reward + (self.gamma * expected_future_rewards) * (1-batch_done)\n",
    "\n",
    "        # loss is measured from error between current and newly expected Q values\n",
    "        loss = F.mse_loss(current_q_values, expected_q_values)\n",
    "\n",
    "        # backpropagation of loss to QNetwork\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    \n",
    "# agent=DQN()\n",
    "# env = TradingEnv()\n",
    "# for i in range(10):\n",
    "#     s = FloatTensor([env.reset()])\n",
    "#     agent.steps_done=100\n",
    "#     print(agent.select_epsilon_greedy_action(s))\n",
    "\n",
    "# agent.run_episode(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "agent=DQN()\n",
    "# env = TradingEnv()\n",
    "# # plt.plot(env.rewards_list)\n",
    "# for i in tqdm(range(10)):\n",
    "#     env = TradingEnv()\n",
    "#     agent.run_episode(env)\n",
    "# agent.plot_cumulative_discounted_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = TradingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f agent.run_episode [agent.run_episode(e) for _ in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.001903 s\n",
       "File: /home/aaruran/Documents/Git/rl-course/project/system.py\n",
       "Function: step at line 123\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   123                                               def step(self, action):\n",
       "   124                                                   \"\"\"\n",
       "   125                                                       Executes an action in the stock environment, using \n",
       "   126                                                       the discrete action space described in: Deep Reinforcement Learning for Trading\n",
       "   127                                                       \n",
       "   128                                                       i.e. -1 is maximally short, 0 is no holdings, 1 is maximally long\n",
       "   129                                                       Inputs: action (one of {-1,0,1})\n",
       "   130                                                       Outputs: a tuple (observation/state, step_reward, is_done, info)\n",
       "   131                                                   \"\"\"\n",
       "   132         1          1.0      1.0      0.1          assert action in [-1, 0, 1], f\"Got {action} but expected one of {-1, 0, 1}\"\n",
       "   133         1         95.0     95.0      5.0          next_price = self._get_normalized_price(diff=1)\n",
       "   134         1         61.0     61.0      3.2          price = self._get_normalized_price()\n",
       "   135         1          1.0      1.0      0.1          r = next_price - price\n",
       "   136         1          0.0      0.0      0.0          mu = 1\n",
       "   137                                                   \n",
       "   138                                           #         sigma = self.data['std'][self.df_index - 1]\n",
       "   139                                           #         sigma_prev = self.data['std'][self.df_index - 2]\n",
       "   140                                                  \n",
       "   141                                           #         term1 = action * self.target_volatility * r / sigma\n",
       "   142                                           #         prev_action = self.actions_list[-1]\n",
       "   143                                           #         term2 = price * TRANSACTION_COST * np.abs(term1 - self.target_volatility * prev_action / sigma_prev)\n",
       "   144                                           #         R = mu*(term1 - term2)\n",
       "   145                                           #         self.rewards_list.append(R)\n",
       "   146                                                   \n",
       "   147                                                   # Additive Returns as reward function\n",
       "   148         1          1.0      1.0      0.1          if action == 1:\n",
       "   149         1          1.0      1.0      0.1              R = r\n",
       "   150                                                   elif action == -1:\n",
       "   151                                                       R = -r\n",
       "   152                                                   elif action == 0:\n",
       "   153                                                       R = 0\n",
       "   154                                               \n",
       "   155                                                   # TODO: Refactor rewards_list, actions_list into a pd.DataFrame so that\n",
       "   156                                                   # 1. I can plot things more easily, and group them together by ticker, and episode number\n",
       "   157                                                   # 2. I can collect rewards_list, actions_list into a single variable\n",
       "   158                                                   \n",
       "   159                                                   \n",
       "   160         1          1.0      1.0      0.1          self.actions_list.append(action)\n",
       "   161         1          1.0      1.0      0.1          self.df_index += 1\n",
       "   162         1       1741.0   1741.0     91.5          return self._get_current_state(), R, self._get_current_timestamp() > self.end, {}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = e.reset()\n",
    "%lprun -f e.step e.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa749d812d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e.prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-253fa5ede371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.actions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agent.rewards_history), len(agent.rewards_history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array(agent.rewards_history)\n",
    "discount_array = np.power(0.8, np.arange(rewards.shape[0]))\n",
    "plt.plot((discount_array[:, None] * rewards).sum(axis=1))\n",
    "# discount_array.shape\n",
    "# rewards.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_cumulative_discounted_rewards(np.array(agent.rewards_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.isna(env.data.iloc[365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.convert_action(FloatTensor([[0]]))\n",
    "# %debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    # for Policy-Gradient methods, e.g. actor-only and actor-critic methods\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, HIDDEN_LAYER)\n",
    "        self.l2 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "        self.l3 = nn.Linear(HIDDEN_LAYER, 2) # 2, for the action\n",
    "\n",
    "    def forward(self, x, d=1, get_log=False):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        if not get_log:\n",
    "            x = F.softmax(self.l3(x), dim=d)\n",
    "        else:\n",
    "            x = F.log_softmax(self.l3(x), dim=d)\n",
    "        return x\n",
    "    \n",
    "    def sample_from_softmax_policy(self, batch_state):\n",
    "        batch_pi = self.forward(batch_state)\n",
    "        batch_size = batch_pi.shape[0]\n",
    "        actions = torch.empty(batch_size, 1)\n",
    "        for i in range(batch_size):\n",
    "            pi = batch_pi[i, :]\n",
    "            dist = torch.distributions.Categorical(pi)\n",
    "            actions[i, 0] = dist.sample().view(1,1)\n",
    "        if use_cuda:\n",
    "            actions = actions.to(batch_state.get_device())\n",
    "        return actions.long()\n",
    "\n",
    "# p = PolicyNetwork()\n",
    "# state = env.reset()\n",
    "# state_tensor = FloatTensor([state]).cuda()\n",
    "# p.cuda()\n",
    "# p.forward(state_tensor, d=1), p.forward(state_tensor, d=-1)\n",
    "# p.sample_from_softmax_policy(torch.cat(5*[state_tensor])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
